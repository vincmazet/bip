# Introduction

ğŸ—ï¸ To do...




<!-- ## Introduction

Le recalage de deux images consiste Ã  trouver la correspondance entre deux images reprÃ©sentant la mÃªme zone.
Les figures ci-dessous prÃ©sentent quelques applications dans lesquelles le recalage est indispensable.

```{figure} vincent4.png
---
height: 250px
name: F:registration:remote-sensing
---
Recalage d'images de tÃ©lÃ©dÃ©tection :
comment combiner ces deux acquisitions diffÃ©rentes de la mÃªme zone pour former une grande image ?
```

```{figure} vincent6.png
---
height: 250px
name: F:registration:medical
---
Recalage en imagerie mÃ©dicale :
pour dÃ©tecter des changements entre deux examens,
il faut que les images soient recalÃ©es (le patient n'est jamais exactement dans la mÃªme position).
```

```{figure} vincent13.png
---
height: 300px
name: F:registration:mosaicing
---
MosaÃ¯que d'image (_image mosaicing_) :
combiner plusieurs images pour en faire une seule grande, en photographie.
```

La {numref}`F:registration:bigpicture` reprÃ©sente le schÃ©ma classique pour effectuer le recalage entre deux images.
Tout l'enjeu est d'estimer la transformation spatiale qui fait correspondre deux images.
Les diffÃ©rentes Ã©tapes reprÃ©sentÃ©es dans cette figure sont dÃ©taillÃ©es dans la suite de ce chapitre.

```{figure} bigpicture.png
---
height: 300px
name: F:registration:bigpicture
---
SchÃ©ma classique du recalage de deux images.
```

% Several scenarios
% â€¢   Monomodal   vs  mul6modal   registra6on
% â€¢   Registra6on of  2D/2D,  2D/3D,  3D/3D,  3D+t,   nD/nD   images
% â€¢   Global  vs  local   /   rigid   vs  deformable  transforma6on


Nevertheless, the majority of the registration methods
consists of the following four steps (see Fig. 1):
â€  Feature detection. Salient and distinctive objects
(closed-boundary regions, edges, contours, line intersec-
tions, corners, etc.) are manually or, preferably, auto-
matically detected. For further processing, these features
can be represented by their point representatives (centers
of gravity, line endings, distinctive points), which are
called control points (CPs) in the literature.
â€  Feature matching. In this step, the correspondence
between the features detected in the sensed image and
those detected in the reference image is established.
Various feature descriptors and similarity measures
along with spatial relationships among the features are
used for that purpose.
â€  Transform model estimation. The type and parameters of
the so-called mapping functions, aligning the sensed
image with the reference image, are estimated. The
parameters of the mapping functions are computed by
means of the established feature correspondence.
â€  Image resampling and transformation. The sensed
image is transformed by means of the mapping
functions. Image values in non-integer coordinates
are computed by the appropriate interpolation
technique. -->